{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cognee transformers torch sentence-transformers accelerate\n",
        "\n",
        "import asyncio\n",
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "from datetime import datetime\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "\n",
        "import cognee"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_AWmxye9Ih4",
        "outputId": "7b021dc9-eb94-47bd-8745-713a3e853427"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cognee in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: aiofiles<24.0.0,>=23.2.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (23.2.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from cognee) (3.12.14)\n",
            "Requirement already satisfied: aiosqlite<1.0.0,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.21.0)\n",
            "Requirement already satisfied: alembic<2,>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.16.4)\n",
            "Requirement already satisfied: dlt<2,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from dlt[sqlalchemy]<2,>=1.9.0->cognee) (1.14.1)\n",
            "Requirement already satisfied: fastapi-users<15.0.0,>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (14.0.1)\n",
            "Requirement already satisfied: fastapi<1.0.0,>=0.115.7 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.116.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.2.0)\n",
            "Requirement already satisfied: instructor<2.0.0,>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.10.0)\n",
            "Requirement already satisfied: jinja2<4,>=3.1.3 in /usr/local/lib/python3.11/dist-packages (from cognee) (3.1.6)\n",
            "Requirement already satisfied: kuzu==0.11.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.11.0)\n",
            "Requirement already satisfied: lancedb<1.0.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.24.2)\n",
            "Requirement already satisfied: langfuse<3,>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (2.60.9)\n",
            "Requirement already satisfied: limits<5,>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (4.8.0)\n",
            "Requirement already satisfied: litellm<1.71.0,>=1.57.4 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.70.4)\n",
            "Requirement already satisfied: matplotlib<4,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from cognee) (3.10.0)\n",
            "Requirement already satisfied: networkx<4,>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from cognee) (3.5)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (3.9.1)\n",
            "Requirement already satisfied: numpy<=4.0.0,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from cognee) (2.0.2)\n",
            "Requirement already satisfied: onnxruntime<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.22.1)\n",
            "Requirement already satisfied: openai<2,>=1.80.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.97.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from cognee) (2.2.2)\n",
            "Requirement already satisfied: pre-commit<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (4.2.0)\n",
            "Requirement already satisfied: pydantic-settings<3,>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (2.10.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from cognee) (2.11.7)\n",
            "Requirement already satisfied: pylance<1.0.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.32.0)\n",
            "Requirement already satisfied: pympler<2.0.0,>=1.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.1)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (5.9.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.1.1)\n",
            "Requirement already satisfied: python-multipart<1.0.0,>=0.0.20 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.0.20)\n",
            "Requirement already satisfied: rdflib<7.2.0,>=7.1.4 in /usr/local/lib/python3.11/dist-packages (from cognee) (7.1.4)\n",
            "Requirement already satisfied: s3fs==2025.3.2 in /usr/local/lib/python3.11/dist-packages (from s3fs[boto3]==2025.3.2->cognee) (2025.3.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from cognee) (1.6.1)\n",
            "Requirement already satisfied: sentry-sdk<3,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from sentry-sdk[fastapi]<3,>=2.9.0->cognee) (2.33.2)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.39 in /usr/local/lib/python3.11/dist-packages (from cognee) (2.0.41)\n",
            "Requirement already satisfied: structlog<26,>=25.2.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (25.4.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from cognee) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from cognee) (4.14.1)\n",
            "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /usr/local/lib/python3.11/dist-packages (from s3fs==2025.3.2->s3fs[boto3]==2025.3.2->cognee) (2.23.2)\n",
            "Requirement already satisfied: fsspec==2025.3.2.* in /usr/local/lib/python3.11/dist-packages (from s3fs==2025.3.2->s3fs[boto3]==2025.3.2->cognee) (2025.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->cognee) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2,>=1.13.3->cognee) (1.1.3)\n",
            "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (8.2.1)\n",
            "Requirement already satisfied: gitpython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.1.44)\n",
            "Requirement already satisfied: giturlparse>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (0.12.0)\n",
            "Requirement already satisfied: hexbytes>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (1.3.1)\n",
            "Requirement already satisfied: humanize>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (4.12.3)\n",
            "Requirement already satisfied: jsonpath-ng>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (1.7.0)\n",
            "Requirement already satisfied: orjson!=3.10.1,!=3.9.11,!=3.9.12,!=3.9.13,!=3.9.14,<4,>=3.6.7 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.11.0)\n",
            "Requirement already satisfied: pathvalidate>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.3.1)\n",
            "Requirement already satisfied: pendulum>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.1.0)\n",
            "Requirement already satisfied: pluggy>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (1.6.0)\n",
            "Requirement already satisfied: pytz>=2022.6 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (2025.2)\n",
            "Requirement already satisfied: requirements-parser>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (0.9.0)\n",
            "Requirement already satisfied: rich-argparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (1.7.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.0.4)\n",
            "Requirement already satisfied: setuptools>=65.6.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (75.2.0)\n",
            "Requirement already satisfied: simplejson>=3.17.5 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.20.1)\n",
            "Requirement already satisfied: sqlglot>=25.4.0 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (25.20.2)\n",
            "Requirement already satisfied: tenacity>=8.0.2 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (8.5.0)\n",
            "Requirement already satisfied: tomlkit>=0.11.3 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (0.13.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (2025.2)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0.0,>=0.115.7->cognee) (0.47.2)\n",
            "Requirement already satisfied: email-validator<2.3,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (2.2.0)\n",
            "Requirement already satisfied: makefun<2.0.0,>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (1.16.0)\n",
            "Requirement already satisfied: pwdlib==0.2.1 in /usr/local/lib/python3.11/dist-packages (from pwdlib[argon2,bcrypt]==0.2.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (0.2.1)\n",
            "Requirement already satisfied: pyjwt==2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]==2.10.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (2.10.1)\n",
            "Requirement already satisfied: argon2-cffi<24,>=23.1.0 in /usr/local/lib/python3.11/dist-packages (from pwdlib[argon2,bcrypt]==0.2.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (23.1.0)\n",
            "Requirement already satisfied: bcrypt<5,>=4.1.2 in /usr/local/lib/python3.11/dist-packages (from pwdlib[argon2,bcrypt]==0.2.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (4.3.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]==2.10.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (43.0.3)\n",
            "Requirement already satisfied: fastapi-users-db-sqlalchemy>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (7.0.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from instructor<2.0.0,>=1.9.1->cognee) (5.6.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor<2.0.0,>=1.9.1->cognee) (0.17.0)\n",
            "Requirement already satisfied: jiter<0.11,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor<2.0.0,>=1.9.1->cognee) (0.10.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor<2.0.0,>=1.9.1->cognee) (2.33.2)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from instructor<2.0.0,>=1.9.1->cognee) (13.9.4)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from instructor<2.0.0,>=1.9.1->cognee) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4,>=3.1.3->cognee) (3.0.2)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from lancedb<1.0.0,>=0.24.0->cognee) (2.1.0)\n",
            "Requirement already satisfied: overrides>=0.7 in /usr/local/lib/python3.11/dist-packages (from lancedb<1.0.0,>=0.24.0->cognee) (7.7.0)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.11/dist-packages (from lancedb<1.0.0,>=0.24.0->cognee) (18.1.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from langfuse<3,>=2.32.0->cognee) (4.9.0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langfuse<3,>=2.32.0->cognee) (2.2.1)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from langfuse<3,>=2.32.0->cognee) (0.28.1)\n",
            "Requirement already satisfied: idna<4.0,>=3.7 in /usr/local/lib/python3.11/dist-packages (from langfuse<3,>=2.32.0->cognee) (3.10)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse<3,>=2.32.0->cognee) (1.17.2)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.11/dist-packages (from limits<5,>=4.4.1->cognee) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm<1.71.0,>=1.57.4->cognee) (8.7.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm<1.71.0,>=1.57.4->cognee) (4.25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.8.3->cognee) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.8.3->cognee) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.8.3->cognee) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.8.3->cognee) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.8.3->cognee) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.8.3->cognee) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->cognee) (1.5.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2.0.0,>=1.0.0->cognee) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2.0.0,>=1.0.0->cognee) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2.0.0,>=1.0.0->cognee) (5.29.5)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.80.1->cognee) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.80.1->cognee) (1.3.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5,>=4.0.1->cognee) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5,>=4.0.1->cognee) (2.6.12)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5,>=4.0.1->cognee) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5,>=4.0.1->cognee) (20.32.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.5->cognee) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.5->cognee) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.6.1->cognee) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.39->cognee) (3.2.3)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs==2025.3.2->s3fs[boto3]==2025.3.2->cognee) (0.12.0)\n",
            "Requirement already satisfied: botocore<1.39.9,>=1.39.7 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs==2025.3.2->s3fs[boto3]==2025.3.2->cognee) (1.39.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs==2025.3.2->s3fs[boto3]==2025.3.2->cognee) (1.0.1)\n",
            "Requirement already satisfied: boto3<1.39.9,>=1.39.7 in /usr/local/lib/python3.11/dist-packages (from aiobotocore[boto3]<3.0.0,>=2.5.4; extra == \"boto3\"->s3fs[boto3]==2025.3.2->cognee) (1.39.8)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator<2.3,>=1.1.0->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (2.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.29->dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.15.4->langfuse<3,>=2.32.0->cognee) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse<3,>=2.32.0->cognee) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm<1.71.0,>=1.57.4->cognee) (3.23.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.11/dist-packages (from jsonpath-ng>=1.5.3->dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (3.11)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<1.71.0,>=1.57.4->cognee) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<1.71.0,>=1.57.4->cognee) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm<1.71.0,>=1.57.4->cognee) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.8.3->cognee) (1.17.0)\n",
            "Requirement already satisfied: types-setuptools>=69.1.0 in /usr/local/lib/python3.11/dist-packages (from requirements-parser>=0.5.0->dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (80.9.0.20250529)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.7.0->instructor<2.0.0,>=1.9.1->cognee) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.7.0->instructor<2.0.0,>=1.9.1->cognee) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.9.0->instructor<2.0.0,>=1.9.1->cognee) (1.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit<5,>=4.0.1->cognee) (0.4.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit<5,>=4.0.1->cognee) (4.3.8)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2.0.0,>=1.0.0->cognee) (10.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi<24,>=23.1.0->pwdlib[argon2,bcrypt]==0.2.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (21.2.0)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3<1.39.9,>=1.39.7->aiobotocore[boto3]<3.0.0,>=2.5.4; extra == \"boto3\"->s3fs[boto3]==2025.3.2->cognee) (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]==2.10.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (1.17.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.29->dlt<2,>=1.9.0->dlt[sqlalchemy]<2,>=1.9.0->cognee) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.7.0->instructor<2.0.0,>=1.9.1->cognee) (0.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]==2.10.1->fastapi-users<15.0.0,>=14.0.1->fastapi-users[sqlalchemy]<15.0.0,>=14.0.1->cognee) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def setup_cognee():\n",
        "    \"\"\"Setup Cognee with proper configuration\"\"\"\n",
        "    try:\n",
        "        await cognee.config.set(\"EMBEDDING_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        await cognee.config.set(\"EMBEDDING_PROVIDER\", \"sentence_transformers\")\n",
        "        print(\"‚úÖ Cognee configured successfully\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Cognee config error: {e}\")\n",
        "        try:\n",
        "            os.environ[\"EMBEDDING_MODEL\"] = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "            os.environ[\"EMBEDDING_PROVIDER\"] = \"sentence_transformers\"\n",
        "            print(\"‚úÖ Cognee configured via environment\")\n",
        "            return True\n",
        "        except Exception as e2:\n",
        "            print(f\"‚ö†Ô∏è Alternative config failed: {e2}\")\n",
        "            return False"
      ],
      "metadata": {
        "id": "fs6_Ck8C9MIU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HuggingFaceLLM:\n",
        "    def __init__(self, model_name=\"microsoft/DialoGPT-medium\"):\n",
        "        print(f\"ü§ñ Loading Hugging Face model: {model_name}\")\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üì± Using device: {self.device}\")\n",
        "\n",
        "        if \"DialoGPT\" in model_name:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        else:\n",
        "            self.generator = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=\"distilgpt2\",\n",
        "                device=0 if self.device == \"cuda\" else -1,\n",
        "                max_length=150,\n",
        "                do_sample=True,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            self.tokenizer = None\n",
        "            self.model = None\n",
        "\n",
        "        print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    def generate_response(self, prompt: str, max_length: int = 100) -> str:\n",
        "        try:\n",
        "            if self.model is not None:\n",
        "                inputs = self.tokenizer.encode(prompt + self.tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.model.generate(\n",
        "                        inputs,\n",
        "                        max_length=inputs.shape[1] + max_length,\n",
        "                        num_return_sequences=1,\n",
        "                        temperature=0.7,\n",
        "                        do_sample=True,\n",
        "                        pad_token_id=self.tokenizer.eos_token_id\n",
        "                    )\n",
        "\n",
        "                response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "                response = response[len(prompt):].strip()\n",
        "                return response if response else \"I understand.\"\n",
        "\n",
        "            else:\n",
        "                result = self.generator(prompt, max_length=max_length, truncation=True)\n",
        "                return result[0]['generated_text'][len(prompt):].strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Generation error: {e}\")\n",
        "            return \"I'm processing that information.\"\n",
        "\n",
        "hf_llm = None"
      ],
      "metadata": {
        "id": "S1BVp7_O9TWj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedAIAgent:\n",
        "    \"\"\"\n",
        "    Advanced AI Agent with persistent memory, learning capabilities,\n",
        "    and multi-domain knowledge processing using Cognee\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_name: str = \"CogneeAgent\"):\n",
        "        self.name = agent_name\n",
        "        self.memory_initialized = False\n",
        "        self.knowledge_domains = []\n",
        "        self.conversation_history = []\n",
        "        self.manual_memory = []\n",
        "\n",
        "    async def initialize_memory(self):\n",
        "        \"\"\"Initialize the agent's memory system and HF model\"\"\"\n",
        "        global hf_llm\n",
        "        if hf_llm is None:\n",
        "            hf_llm = HuggingFaceLLM(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "        setup_success = await setup_cognee()\n",
        "\n",
        "        try:\n",
        "            await cognee.prune()\n",
        "            print(f\"‚úÖ {self.name} memory system initialized\")\n",
        "            self.memory_initialized = True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Memory initialization warning: {e}\")\n",
        "            self.memory_initialized = True\n",
        "\n",
        "    async def learn_from_text(self, text: str, domain: str = \"general\"):\n",
        "        \"\"\"Add knowledge to the agent's memory with domain tagging\"\"\"\n",
        "        if not self.memory_initialized:\n",
        "            await self.initialize_memory()\n",
        "\n",
        "        enhanced_text = f\"[DOMAIN: {domain}] [TIMESTAMP: {datetime.now().isoformat()}]\\n{text}\"\n",
        "\n",
        "        try:\n",
        "            await cognee.add(enhanced_text)\n",
        "            await cognee.cognify()\n",
        "            if domain not in self.knowledge_domains:\n",
        "                self.knowledge_domains.append(domain)\n",
        "            print(f\"üìö Learned new knowledge in domain: {domain}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Learning error: {e}\")\n",
        "            try:\n",
        "                await cognee.add(text)\n",
        "                await cognee.cognify()\n",
        "                if domain not in self.knowledge_domains:\n",
        "                    self.knowledge_domains.append(domain)\n",
        "                print(f\"üìö Learned (simplified): {domain}\")\n",
        "                return True\n",
        "            except Exception as e2:\n",
        "                print(f\"‚ùå Simplified learning failed: {e2}\")\n",
        "                if not hasattr(self, 'manual_memory'):\n",
        "                    self.manual_memory = []\n",
        "                self.manual_memory.append({\"text\": text, \"domain\": domain})\n",
        "                if domain not in self.knowledge_domains:\n",
        "                    self.knowledge_domains.append(domain)\n",
        "                print(f\"üìö Stored in manual memory: {domain}\")\n",
        "                return True\n",
        "\n",
        "    async def learn_from_documents(self, documents: List[Dict[str, str]]):\n",
        "        \"\"\"Batch learning from multiple documents\"\"\"\n",
        "        print(f\"üìñ Processing {len(documents)} documents...\")\n",
        "\n",
        "        for i, doc in enumerate(documents):\n",
        "            text = doc.get(\"content\", \"\")\n",
        "            domain = doc.get(\"domain\", \"general\")\n",
        "            title = doc.get(\"title\", f\"Document_{i+1}\")\n",
        "\n",
        "            enhanced_content = f\"Title: {title}\\n{text}\"\n",
        "            await self.learn_from_text(enhanced_content, domain)\n",
        "\n",
        "            if i % 3 == 0:\n",
        "                print(f\"  Processed {i+1}/{len(documents)} documents\")\n",
        "\n",
        "    async def query_knowledge(self, question: str, domain_filter: str = None) -> List[str]:\n",
        "        \"\"\"Query the agent's knowledge base with optional domain filtering\"\"\"\n",
        "        try:\n",
        "            if domain_filter:\n",
        "                enhanced_query = f\"[DOMAIN: {domain_filter}] {question}\"\n",
        "            else:\n",
        "                enhanced_query = question\n",
        "\n",
        "            search_results = await cognee.search(\"SIMILARITY\", enhanced_query)\n",
        "\n",
        "            results = []\n",
        "            for result in search_results:\n",
        "                if hasattr(result, 'text'):\n",
        "                    results.append(result.text)\n",
        "                elif hasattr(result, 'content'):\n",
        "                    results.append(result.content)\n",
        "                elif hasattr(result, 'value'):\n",
        "                    results.append(str(result.value))\n",
        "                elif isinstance(result, dict):\n",
        "                    content = result.get('text') or result.get('content') or result.get('data') or result.get('value')\n",
        "                    if content:\n",
        "                        results.append(str(content))\n",
        "                    else:\n",
        "                        results.append(str(result))\n",
        "                elif isinstance(result, str):\n",
        "                    results.append(result)\n",
        "                else:\n",
        "                    result_str = str(result)\n",
        "                    if len(result_str) > 10:\n",
        "                        results.append(result_str)\n",
        "\n",
        "            if not results and hasattr(self, 'manual_memory'):\n",
        "                for item in self.manual_memory:\n",
        "                    if domain_filter and item['domain'] != domain_filter:\n",
        "                        continue\n",
        "                    if any(word.lower() in item['text'].lower() for word in question.split()):\n",
        "                        results.append(item['text'])\n",
        "\n",
        "            return results[:5]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"üîç Search error: {e}\")\n",
        "            results = []\n",
        "            if hasattr(self, 'manual_memory'):\n",
        "                for item in self.manual_memory:\n",
        "                    if domain_filter and item['domain'] != domain_filter:\n",
        "                        continue\n",
        "                    if any(word.lower() in item['text'].lower() for word in question.split()):\n",
        "                        results.append(item['text'])\n",
        "            return results[:5]\n",
        "\n",
        "    async def reasoning_chain(self, question: str) -> Dict[str, Any]:\n",
        "        \"\"\"Advanced reasoning using retrieved knowledge\"\"\"\n",
        "        print(f\"ü§î Processing question: {question}\")\n",
        "\n",
        "        relevant_info = await self.query_knowledge(question)\n",
        "\n",
        "        analysis = {\n",
        "            \"question\": question,\n",
        "            \"relevant_knowledge\": relevant_info,\n",
        "            \"domains_searched\": self.knowledge_domains,\n",
        "            \"confidence\": min(len(relevant_info) / 3.0, 1.0),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        if relevant_info and len(relevant_info) > 0:\n",
        "            reasoning = self._synthesize_answer(question, relevant_info)\n",
        "            analysis[\"reasoning\"] = reasoning\n",
        "            analysis[\"answer\"] = self._extract_key_points(relevant_info)\n",
        "        else:\n",
        "            analysis[\"reasoning\"] = \"No relevant knowledge found in memory\"\n",
        "            analysis[\"answer\"] = \"I don't have information about this topic in my current knowledge base.\"\n",
        "\n",
        "        return analysis\n",
        "\n",
        "\n",
        "    def _synthesize_answer(self, question: str, knowledge_pieces: List[str]) -> str:\n",
        "        \"\"\"AI-powered answer synthesis using Hugging Face model\"\"\"\n",
        "        global hf_llm\n",
        "\n",
        "        if not knowledge_pieces:\n",
        "            return \"No relevant information found in my knowledge base.\"\n",
        "\n",
        "        context = \" \".join(knowledge_pieces[:2])\n",
        "        context = context[:300]\n",
        "\n",
        "        prompt = f\"Based on this information: {context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "        try:\n",
        "            if hf_llm:\n",
        "                synthesized = hf_llm.generate_response(prompt, max_length=80)\n",
        "                return synthesized if synthesized else f\"Based on my knowledge: {context[:100]}...\"\n",
        "            else:\n",
        "                return f\"From my analysis: {context[:150]}...\"\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Synthesis error: {e}\")\n",
        "            return f\"Based on my knowledge: {context[:100]}...\"\n",
        "\n",
        "    def _extract_key_points(self, knowledge_pieces: List[str]) -> List[str]:\n",
        "        \"\"\"Extract key points from retrieved knowledge\"\"\"\n",
        "        key_points = []\n",
        "        for piece in knowledge_pieces:\n",
        "            clean_piece = piece.replace(\"[DOMAIN:\", \"\").replace(\"[TIMESTAMP:\", \"\")\n",
        "            sentences = clean_piece.split('.')\n",
        "            if len(sentences) > 0 and len(sentences[0].strip()) > 10:\n",
        "                key_points.append(sentences[0].strip() + \".\")\n",
        "\n",
        "        return key_points[:3]\n",
        "\n",
        "    async def conversational_agent(self, user_input: str) -> str:\n",
        "        \"\"\"Main conversational interface with HF model integration\"\"\"\n",
        "        global hf_llm\n",
        "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        if any(word in user_input.lower() for word in [\"learn\", \"remember\", \"add\", \"teach\"]):\n",
        "            content_to_learn = user_input.replace(\"learn this:\", \"\").replace(\"remember:\", \"\").strip()\n",
        "            await self.learn_from_text(content_to_learn, \"conversation\")\n",
        "            response = \"I've stored that information in my memory! What else would you like to teach me?\"\n",
        "\n",
        "        elif user_input.lower().startswith((\"what\", \"how\", \"why\", \"when\", \"where\", \"who\", \"tell me\")):\n",
        "            analysis = await self.reasoning_chain(user_input)\n",
        "\n",
        "            if analysis[\"relevant_knowledge\"] and hf_llm:\n",
        "                context = \" \".join(analysis[\"relevant_knowledge\"][:2])[:200]\n",
        "                prompt = f\"Question: {user_input}\\nKnowledge: {context}\\nFriendly response:\"\n",
        "                ai_response = hf_llm.generate_response(prompt, max_length=60)\n",
        "                response = ai_response if ai_response else \"Here's what I found in my knowledge base.\"\n",
        "            else:\n",
        "                response = \"I don't have specific information about that topic in my current knowledge base.\"\n",
        "\n",
        "        else:\n",
        "            relevant_context = await self.query_knowledge(user_input)\n",
        "\n",
        "            if hf_llm:\n",
        "                context_info = \"\"\n",
        "                if relevant_context:\n",
        "                    context_info = f\" I know that: {relevant_context[0][:100]}...\"\n",
        "\n",
        "                conversation_prompt = f\"User says: {user_input}{context_info}\\nI respond:\"\n",
        "                response = hf_llm.generate_response(conversation_prompt, max_length=50)\n",
        "\n",
        "                if not response or len(response.strip()) < 3:\n",
        "                    response = \"That's interesting! I'm learning from our conversation.\"\n",
        "            else:\n",
        "                response = \"I'm listening and learning from our conversation.\"\n",
        "\n",
        "        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "        return response"
      ],
      "metadata": {
        "id": "F6Oc20bq9h8Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOYTdcWz58PB",
        "outputId": "12a4993a-2449-494e-ed1f-30fd125a736c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Advanced AI Agent Tutorial with Hugging Face Models...\n",
            "ü§ó Using free models from Hugging Face Hub\n",
            "üíª Running on CPU\n",
            "üöÄ Advanced AI Agent with Cognee Tutorial\n",
            "==================================================\n",
            "ü§ñ Loading Hugging Face model: microsoft/DialoGPT-medium\n",
            "üì± Using device: cpu\n",
            "‚úÖ Model loaded successfully!\n",
            "‚ö†Ô∏è Cognee config error: type object 'config' has no attribute 'set'\n",
            "‚úÖ Cognee configured via environment\n",
            "‚ö†Ô∏è Memory initialization warning: object prune can't be used in 'await' expression\n",
            "\n",
            "üìö DEMO 1: Multi-domain Learning\n",
            "üìñ Processing 4 documents...\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: programming\n",
            "  Processed 1/4 documents\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: science\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: technology\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: environment\n",
            "  Processed 4/4 documents\n",
            "\n",
            "üîç DEMO 2: Knowledge Retrieval & Reasoning\n",
            "\n",
            "‚ùì Question: What do you know about Python programming?\n",
            "ü§î Processing question: What do you know about Python programming?\n",
            "üîç Search error: 'str' object has no attribute 'value'\n",
            "üí° Answer: ['Title: Python Basics\\nPython is a high-level programming language known for its simplicity and readability.']\n",
            "üéØ Confidence: 0.33\n",
            "\n",
            "‚ùì Question: How does climate change relate to energy?\n",
            "ü§î Processing question: How does climate change relate to energy?\n",
            "üîç Search error: 'str' object has no attribute 'value'\n",
            "üí° Answer: ['Title: Climate Science\\nClimate change refers to long-term shifts in global temperatures and weather patterns.']\n",
            "üéØ Confidence: 0.33\n",
            "\n",
            "‚ùì Question: What are the ethical considerations in AI?\n",
            "ü§î Processing question: What are the ethical considerations in AI?\n",
            "üîç Search error: 'str' object has no attribute 'value'\n",
            "üí° Answer: ['Title: Python Basics\\nPython is a high-level programming language known for its simplicity and readability.', 'Title: Climate Science\\nClimate change refers to long-term shifts in global temperatures and weather patterns.', 'Title: AI Ethics\\nAI ethics involves ensuring artificial intelligence systems are developed and deployed responsibly, considering fairness, transparency, accountability, and potential societal impacts.']\n",
            "üéØ Confidence: 1.00\n",
            "\n",
            "üí¨ DEMO 3: Conversational Agent\n",
            "\n",
            "üó£Ô∏è User: Learn this: Machine learning is a subset of AI that enables computers to learn without explicit programming\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: conversation\n",
            "ü§ñ Agent: I've stored that information in my memory! What else would you like to teach me?\n",
            "\n",
            "üó£Ô∏è User: What is machine learning?\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: conversation\n",
            "ü§ñ Agent: I've stored that information in my memory! What else would you like to teach me?\n",
            "\n",
            "üó£Ô∏è User: How does it relate to Python?\n",
            "ü§î Processing question: How does it relate to Python?\n",
            "üîç Search error: 'str' object has no attribute 'value'\n",
            "ü§ñ Agent: Python is a programming language, not a language.\n",
            "\n",
            "üó£Ô∏è User: Remember that neural networks are inspired by biological neurons\n",
            "‚ùå Learning error: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "‚ùå Simplified learning failed: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
            "If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n",
            "üìö Stored in manual memory: conversation\n",
            "ü§ñ Agent: I've stored that information in my memory! What else would you like to teach me?\n",
            "\n",
            "üìä DEMO 4: Agent Knowledge Summary\n",
            "Knowledge domains: ['programming', 'science', 'technology', 'environment', 'conversation']\n",
            "Conversation history: 8 exchanges\n",
            "\n",
            "üéØ Domain-specific search:\n",
            "üîç Search error: 'str' object has no attribute 'value'\n",
            "Programming knowledge: 1 results found\n",
            "\n",
            "‚úÖ Tutorial completed! You've learned:\n",
            "‚Ä¢ How to set up Cognee with Hugging Face models\n",
            "‚Ä¢ AI-powered response generation\n",
            "‚Ä¢ Multi-domain knowledge management\n",
            "‚Ä¢ Advanced reasoning and retrieval\n",
            "‚Ä¢ Conversational agent with memory\n",
            "‚Ä¢ Free GPU-accelerated inference\n"
          ]
        }
      ],
      "source": [
        "async def main():\n",
        "    print(\"üöÄ Advanced AI Agent with Cognee Tutorial\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    agent = AdvancedAIAgent(\"TutorialAgent\")\n",
        "    await agent.initialize_memory()\n",
        "\n",
        "    print(\"\\nüìö DEMO 1: Multi-domain Learning\")\n",
        "    sample_documents = [\n",
        "        {\n",
        "            \"title\": \"Python Basics\",\n",
        "            \"content\": \"Python is a high-level programming language known for its simplicity and readability. It supports multiple programming paradigms including procedural, object-oriented, and functional programming.\",\n",
        "            \"domain\": \"programming\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Climate Science\",\n",
        "            \"content\": \"Climate change refers to long-term shifts in global temperatures and weather patterns. Human activities, particularly burning fossil fuels, are the primary driver of recent climate change.\",\n",
        "            \"domain\": \"science\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"AI Ethics\",\n",
        "            \"content\": \"AI ethics involves ensuring artificial intelligence systems are developed and deployed responsibly, considering fairness, transparency, accountability, and potential societal impacts.\",\n",
        "            \"domain\": \"technology\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Sustainable Energy\",\n",
        "            \"content\": \"Renewable energy sources like solar, wind, and hydroelectric power are crucial for reducing carbon emissions and creating a sustainable energy future.\",\n",
        "            \"domain\": \"environment\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    await agent.learn_from_documents(sample_documents)\n",
        "\n",
        "    print(\"\\nüîç DEMO 2: Knowledge Retrieval & Reasoning\")\n",
        "    test_questions = [\n",
        "        \"What do you know about Python programming?\",\n",
        "        \"How does climate change relate to energy?\",\n",
        "        \"What are the ethical considerations in AI?\"\n",
        "    ]\n",
        "\n",
        "    for question in test_questions:\n",
        "        print(f\"\\n‚ùì Question: {question}\")\n",
        "        analysis = await agent.reasoning_chain(question)\n",
        "        print(f\"üí° Answer: {analysis.get('answer', 'No answer generated')}\")\n",
        "        print(f\"üéØ Confidence: {analysis.get('confidence', 0):.2f}\")\n",
        "\n",
        "    print(\"\\nüí¨ DEMO 3: Conversational Agent\")\n",
        "    conversation_inputs = [\n",
        "        \"Learn this: Machine learning is a subset of AI that enables computers to learn without explicit programming\",\n",
        "        \"What is machine learning?\",\n",
        "        \"How does it relate to Python?\",\n",
        "        \"Remember that neural networks are inspired by biological neurons\"\n",
        "    ]\n",
        "\n",
        "    for user_input in conversation_inputs:\n",
        "        print(f\"\\nüó£Ô∏è User: {user_input}\")\n",
        "        response = await agent.conversational_agent(user_input)\n",
        "        print(f\"ü§ñ Agent: {response}\")\n",
        "\n",
        "    print(f\"\\nüìä DEMO 4: Agent Knowledge Summary\")\n",
        "    print(f\"Knowledge domains: {agent.knowledge_domains}\")\n",
        "    print(f\"Conversation history: {len(agent.conversation_history)} exchanges\")\n",
        "\n",
        "    print(f\"\\nüéØ Domain-specific search:\")\n",
        "    programming_results = await agent.query_knowledge(\"programming concepts\", \"programming\")\n",
        "    print(f\"Programming knowledge: {len(programming_results)} results found\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Advanced AI Agent Tutorial with Hugging Face Models...\")\n",
        "    print(\"ü§ó Using free models from Hugging Face Hub\")\n",
        "    print(\"üì± GPU acceleration available!\" if torch.cuda.is_available() else \"üíª Running on CPU\")\n",
        "\n",
        "    try:\n",
        "        await main()\n",
        "    except RuntimeError:\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "        asyncio.run(main())\n",
        "\n",
        "    print(\"\\n‚úÖ Tutorial completed! You've learned:\")\n",
        "    print(\"‚Ä¢ How to set up Cognee with Hugging Face models\")\n",
        "    print(\"‚Ä¢ AI-powered response generation\")\n",
        "    print(\"‚Ä¢ Multi-domain knowledge management\")\n",
        "    print(\"‚Ä¢ Advanced reasoning and retrieval\")\n",
        "    print(\"‚Ä¢ Conversational agent with memory\")\n",
        "    print(\"‚Ä¢ Free GPU-accelerated inference\")"
      ]
    }
  ]
}