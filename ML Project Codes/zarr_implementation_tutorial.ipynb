{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install zarr numcodecs -q\n",
        "import zarr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numcodecs import Blosc, Delta, FixedScaleOffset\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"Zarr version: {zarr.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "print(\"=== BASIC ZARR OPERATIONS ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1l8pfwNQZ6B",
        "outputId": "e9051598-7945-4366-c151-321a9d7b6950"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zarr version: 3.1.2\n",
            "NumPy version: 2.0.2\n",
            "=== BASIC ZARR OPERATIONS ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tutorial_dir = Path(tempfile.mkdtemp(prefix=\"zarr_tutorial_\"))\n",
        "print(f\"Working directory: {tutorial_dir}\")\n",
        "\n",
        "z1 = zarr.zeros((1000, 1000), chunks=(100, 100), dtype='f4',\n",
        "                store=str(tutorial_dir / 'basic_array.zarr'), zarr_format=2)\n",
        "z2 = zarr.ones((500, 500, 10), chunks=(100, 100, 5), dtype='i4',\n",
        "               store=str(tutorial_dir / 'multi_dim.zarr'), zarr_format=2)\n",
        "\n",
        "print(f\"2D Array shape: {z1.shape}, chunks: {z1.chunks}, dtype: {z1.dtype}\")\n",
        "print(f\"3D Array shape: {z2.shape}, chunks: {z2.chunks}, dtype: {z2.dtype}\")\n",
        "\n",
        "z1[100:200, 100:200] = np.random.random((100, 100)).astype('f4')\n",
        "z2[:, :, 0] = np.arange(500*500).reshape(500, 500)\n",
        "\n",
        "print(f\"Memory usage estimate: {z1.nbytes_stored() / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW_hhoB1QcVQ",
        "outputId": "607fcb44-9092-46d8-bc44-78f5c02c7682"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /tmp/zarr_tutorial_sx_lklbv\n",
            "2D Array shape: (1000, 1000), chunks: (100, 100), dtype: float32\n",
            "3D Array shape: (500, 500, 10), chunks: (100, 100, 5), dtype: int32\n",
            "Memory usage estimate: 0.03 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== ADVANCED CHUNKING ===\")\n",
        "\n",
        "time_steps, height, width = 365, 1000, 2000\n",
        "time_series = zarr.zeros(\n",
        "    (time_steps, height, width),\n",
        "    chunks=(30, 250, 500),\n",
        "    dtype='f4',\n",
        "    store=str(tutorial_dir / 'time_series.zarr'),\n",
        "    zarr_format=2\n",
        ")\n",
        "\n",
        "for t in range(0, time_steps, 30):\n",
        "    end_t = min(t + 30, time_steps)\n",
        "    seasonal = np.sin(2 * np.pi * np.arange(t, end_t) / 365)[:, None, None]\n",
        "    spatial = np.random.normal(20, 5, (end_t - t, height, width))\n",
        "    time_series[t:end_t] = (spatial + 10 * seasonal).astype('f4')\n",
        "\n",
        "print(f\"Time series created: {time_series.shape}\")\n",
        "print(f\"Approximate chunks created\")\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "temporal_slice = time_series[:, 500, 1000]\n",
        "temporal_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "spatial_slice = time_series[100, :200, :200]\n",
        "spatial_time = time.time() - start\n",
        "\n",
        "print(f\"Temporal access time: {temporal_time:.4f}s\")\n",
        "print(f\"Spatial access time: {spatial_time:.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByRYCPZBQjHH",
        "outputId": "c28f5578-b08e-41ec-9e04-621e5bee8c87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ADVANCED CHUNKING ===\n",
            "Time series created: (365, 1000, 2000)\n",
            "Approximate chunks created\n",
            "Temporal access time: 0.2720s\n",
            "Spatial access time: 0.0223s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== COMPRESSION AND CODECS ===\")\n",
        "\n",
        "data = np.random.randint(0, 1000, (1000, 1000), dtype='i4')\n",
        "\n",
        "from zarr.codecs import BloscCodec, BytesCodec\n",
        "\n",
        "z_none = zarr.array(data, chunks=(100, 100),\n",
        "                   codecs=[BytesCodec()],\n",
        "                   store=str(tutorial_dir / 'no_compress.zarr'))\n",
        "\n",
        "z_lz4 = zarr.array(data, chunks=(100, 100),\n",
        "                   codecs=[BytesCodec(), BloscCodec(cname='lz4', clevel=5)],\n",
        "                   store=str(tutorial_dir / 'lz4_compress.zarr'))\n",
        "\n",
        "z_zstd = zarr.array(data, chunks=(100, 100),\n",
        "                    codecs=[BytesCodec(), BloscCodec(cname='zstd', clevel=9)],\n",
        "                    store=str(tutorial_dir / 'zstd_compress.zarr'))\n",
        "\n",
        "sequential_data = np.cumsum(np.random.randint(-5, 6, (1000, 1000)), axis=1)\n",
        "z_delta = zarr.array(sequential_data, chunks=(100, 100),\n",
        "                     codecs=[BytesCodec(), BloscCodec(cname='zstd', clevel=5)],\n",
        "                     store=str(tutorial_dir / 'sequential_compress.zarr'))\n",
        "\n",
        "sizes = {\n",
        "    'No compression': z_none.nbytes_stored(),\n",
        "    'LZ4': z_lz4.nbytes_stored(),\n",
        "    'ZSTD': z_zstd.nbytes_stored(),\n",
        "    'Sequential+ZSTD': z_delta.nbytes_stored()\n",
        "}\n",
        "\n",
        "print(\"Compression comparison:\")\n",
        "original_size = data.nbytes\n",
        "for name, size in sizes.items():\n",
        "    ratio = size / original_size\n",
        "    print(f\"{name}: {size/1024**2:.2f} MB (ratio: {ratio:.3f})\")\n",
        "\n",
        "print(\"\\n=== HIERARCHICAL DATA ORGANIZATION ===\")\n",
        "\n",
        "root = zarr.open_group(str(tutorial_dir / 'experiment.zarr'), mode='w')\n",
        "\n",
        "raw_data = root.create_group('raw_data')\n",
        "processed = root.create_group('processed')\n",
        "metadata = root.create_group('metadata')\n",
        "\n",
        "raw_data.create_dataset('images', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='u2')\n",
        "raw_data.create_dataset('timestamps', shape=(100,), dtype='datetime64[ns]')\n",
        "\n",
        "processed.create_dataset('normalized', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='f4')\n",
        "processed.create_dataset('features', shape=(100, 50), chunks=(20, 50), dtype='f4')\n",
        "\n",
        "root.attrs['experiment_id'] = 'EXP_2024_001'\n",
        "root.attrs['description'] = 'Advanced Zarr tutorial demonstration'\n",
        "root.attrs['created'] = str(np.datetime64('2024-01-01'))\n",
        "\n",
        "raw_data.attrs['instrument'] = 'Synthetic Camera'\n",
        "raw_data.attrs['resolution'] = [512, 512]\n",
        "processed.attrs['normalization'] = 'z-score'\n",
        "\n",
        "timestamps = np.datetime64('2024-01-01') + np.arange(100) * np.timedelta64(1, 'h')\n",
        "raw_data['timestamps'][:] = timestamps\n",
        "\n",
        "for i in range(100):\n",
        "    frame = np.random.poisson(100 + 50 * np.sin(2 * np.pi * i / 100), (512, 512)).astype('u2')\n",
        "    raw_data['images'][i] = frame\n",
        "\n",
        "print(f\"Created hierarchical structure with {len(list(root.group_keys()))} groups\")\n",
        "print(f\"Data arrays and groups created successfully\")\n",
        "\n",
        "print(\"\\n=== ADVANCED INDEXING ===\")\n",
        "\n",
        "volume_data = zarr.zeros((50, 20, 256, 256), chunks=(5, 5, 64, 64), dtype='f4',\n",
        "                        store=str(tutorial_dir / 'volume.zarr'), zarr_format=2)\n",
        "\n",
        "for t in range(50):\n",
        "    for z in range(20):\n",
        "        y, x = np.ogrid[:256, :256]\n",
        "        center_y, center_x = 128 + 20*np.sin(t*0.1), 128 + 20*np.cos(t*0.1)\n",
        "        focus_quality = 1 - abs(z - 10) / 10\n",
        "\n",
        "        signal = focus_quality * np.exp(-((y-center_y)**2 + (x-center_x)**2) / (50**2))\n",
        "        noise = 0.1 * np.random.random((256, 256))\n",
        "        volume_data[t, z] = (signal + noise).astype('f4')\n",
        "\n",
        "print(\"Various slicing operations:\")\n",
        "\n",
        "max_projection = np.max(volume_data[:, 10], axis=0)\n",
        "print(f\"Max projection shape: {max_projection.shape}\")\n",
        "\n",
        "z_stack = volume_data[25, :, 100:156, 100:156]\n",
        "print(f\"Z-stack subset: {z_stack.shape}\")\n",
        "\n",
        "bright_pixels = volume_data[volume_data > 0.5]\n",
        "print(f\"Pixels above threshold: {len(bright_pixels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE1TVqsrQpPA",
        "outputId": "0d8c1acb-7c0d-4458-f798-69cd8fff74a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== COMPRESSION AND CODECS ===\n",
            "Compression comparison:\n",
            "No compression: 3.82 MB (ratio: 1.000)\n",
            "LZ4: 1.64 MB (ratio: 0.430)\n",
            "ZSTD: 1.25 MB (ratio: 0.328)\n",
            "Sequential+ZSTD: 0.98 MB (ratio: 0.256)\n",
            "\n",
            "=== HIERARCHICAL DATA ORGANIZATION ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3126159196.py:45: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  raw_data.create_dataset('images', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='u2')\n",
            "/tmp/ipython-input-3126159196.py:46: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  raw_data.create_dataset('timestamps', shape=(100,), dtype='datetime64[ns]')\n",
            "/tmp/ipython-input-3126159196.py:48: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  processed.create_dataset('normalized', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='f4')\n",
            "/tmp/ipython-input-3126159196.py:49: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  processed.create_dataset('features', shape=(100, 50), chunks=(20, 50), dtype='f4')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created hierarchical structure with 3 groups\n",
            "Data arrays and groups created successfully\n",
            "\n",
            "=== ADVANCED INDEXING ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== PERFORMANCE OPTIMIZATION ===\")\n",
        "\n",
        "def process_chunk_serial(data, func):\n",
        "    results = []\n",
        "    for i in range(0, len(data), 100):\n",
        "        chunk = data[i:i+100]\n",
        "        results.append(func(chunk))\n",
        "    return np.concatenate(results)\n",
        "\n",
        "def gaussian_filter_1d(x, sigma=1.0):\n",
        "    kernel_size = int(4 * sigma)\n",
        "    if kernel_size % 2 == 0:\n",
        "        kernel_size += 1\n",
        "    kernel = np.exp(-0.5 * ((np.arange(kernel_size) - kernel_size//2) / sigma)**2)\n",
        "    kernel = kernel / kernel.sum()\n",
        "    return np.convolve(x.astype(float), kernel, mode='same')\n",
        "\n",
        "large_array = zarr.random.random((10000,), chunks=(1000,),\n",
        "                               store=str(tutorial_dir / 'large.zarr'), zarr_format=2)\n",
        "\n",
        "start_time = time.time()\n",
        "chunk_size = 1000\n",
        "filtered_data = []\n",
        "for i in range(0, len(large_array), chunk_size):\n",
        "    end_idx = min(i + chunk_size, len(large_array))\n",
        "    chunk_data = large_array[i:end_idx]\n",
        "    smoothed = np.convolve(chunk_data, np.ones(5)/5, mode='same')\n",
        "    filtered_data.append(smoothed)\n",
        "\n",
        "result = np.concatenate(filtered_data)\n",
        "processing_time = time.time() - start_time\n",
        "\n",
        "print(f\"Chunk-aware processing time: {processing_time:.4f}s\")\n",
        "print(f\"Processed {len(large_array):,} elements\")\n",
        "\n",
        "print(\"\\n=== VISUALIZATION ===\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Advanced Zarr Tutorial - Data Visualization', fontsize=16)\n",
        "\n",
        "axes[0,0].plot(temporal_slice)\n",
        "axes[0,0].set_title('Temporal Evolution (Single Pixel)')\n",
        "axes[0,0].set_xlabel('Day of Year')\n",
        "axes[0,0].set_ylabel('Temperature')\n",
        "\n",
        "im1 = axes[0,1].imshow(spatial_slice, cmap='viridis')\n",
        "axes[0,1].set_title('Spatial Pattern (Day 100)')\n",
        "plt.colorbar(im1, ax=axes[0,1])\n",
        "\n",
        "methods = list(sizes.keys())\n",
        "ratios = [sizes[m]/original_size for m in methods]\n",
        "axes[0,2].bar(range(len(methods)), ratios)\n",
        "axes[0,2].set_xticks(range(len(methods)))\n",
        "axes[0,2].set_xticklabels(methods, rotation=45)\n",
        "axes[0,2].set_title('Compression Ratios')\n",
        "axes[0,2].set_ylabel('Size Ratio')\n",
        "\n",
        "axes[1,0].imshow(max_projection, cmap='hot')\n",
        "axes[1,0].set_title('Max Intensity Projection')\n",
        "\n",
        "z_profile = np.mean(volume_data[25, :, 120:136, 120:136], axis=(1,2))\n",
        "axes[1,1].plot(z_profile, 'o-')\n",
        "axes[1,1].set_title('Z-Profile (Center Region)')\n",
        "axes[1,1].set_xlabel('Z-slice')\n",
        "axes[1,1].set_ylabel('Mean Intensity')\n",
        "\n",
        "axes[1,2].plot(result[:1000])\n",
        "axes[1,2].set_title('Processed Signal (First 1000 points)')\n",
        "axes[1,2].set_xlabel('Sample')\n",
        "axes[1,2].set_ylabel('Amplitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NABT97sZQtOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eSINj0GMvoy"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== TUTORIAL SUMMARY ===\")\n",
        "print(\"Zarr features demonstrated:\")\n",
        "print(\"âœ“ Multi-dimensional array creation and manipulation\")\n",
        "print(\"âœ“ Optimal chunking strategies for different access patterns\")\n",
        "print(\"âœ“ Advanced compression with multiple codecs\")\n",
        "print(\"âœ“ Hierarchical data organization with metadata\")\n",
        "print(\"âœ“ Advanced indexing and data views\")\n",
        "print(\"âœ“ Performance optimization techniques\")\n",
        "print(\"âœ“ Integration with visualization tools\")\n",
        "\n",
        "def show_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
        "    if current_depth > max_depth:\n",
        "        return\n",
        "    items = sorted(path.iterdir())\n",
        "    for i, item in enumerate(items):\n",
        "        is_last = i == len(items) - 1\n",
        "        current_prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
        "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
        "        if item.is_dir() and current_depth < max_depth:\n",
        "            next_prefix = prefix + (\"    \" if is_last else \"â”‚   \")\n",
        "            show_tree(item, next_prefix, max_depth, current_depth + 1)\n",
        "\n",
        "print(f\"\\nFiles created in {tutorial_dir}:\")\n",
        "show_tree(tutorial_dir)\n",
        "\n",
        "print(f\"\\nTotal disk usage: {sum(f.stat().st_size for f in tutorial_dir.rglob('*') if f.is_file()) / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Advanced Zarr tutorial completed successfully!\")"
      ]
    }
  ]
}