{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/m-bain/whisperX.git\n",
        "!pip install -q pandas matplotlib seaborn\n",
        "\n",
        "import whisperx\n",
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display, HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "CONFIG = {\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"compute_type\": \"float16\" if torch.cuda.is_available() else \"int8\",\n",
        "    \"batch_size\": 16,\n",
        "    \"model_size\": \"base\",\n",
        "    \"language\": None,\n",
        "}\n",
        "\n",
        "print(f\"ðŸš€ Running on: {CONFIG['device']}\")\n",
        "print(f\"ðŸ“Š Compute type: {CONFIG['compute_type']}\")\n",
        "print(f\"ðŸŽ¯ Model: {CONFIG['model_size']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-TwDlT6wWs0",
        "outputId": "f81c87b8-6e91-4191-eb41-09b433234af5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "ðŸš€ Running on: cuda\n",
            "ðŸ“Š Compute type: float16\n",
            "ðŸŽ¯ Model: base\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_sample_audio():\n",
        "    \"\"\"Download a sample audio file for testing\"\"\"\n",
        "    !wget -q -O sample.mp3 https://github.com/mozilla-extensions/speaktome/raw/master/content/cv-valid-dev/sample-000000.mp3\n",
        "    print(\"âœ… Sample audio downloaded\")\n",
        "    return \"sample.mp3\"\n",
        "\n",
        "def load_and_analyze_audio(audio_path):\n",
        "    \"\"\"Load audio and display basic info\"\"\"\n",
        "    audio = whisperx.load_audio(audio_path)\n",
        "    duration = len(audio) / 16000\n",
        "    print(f\"ðŸ“ Audio: {Path(audio_path).name}\")\n",
        "    print(f\"â±ï¸  Duration: {duration:.2f} seconds\")\n",
        "    print(f\"ðŸŽµ Sample rate: 16000 Hz\")\n",
        "    display(Audio(audio_path))\n",
        "    return audio, duration\n",
        "\n",
        "def transcribe_audio(audio, model_size=CONFIG[\"model_size\"], language=None):\n",
        "    \"\"\"Transcribe audio using WhisperX (batched inference)\"\"\"\n",
        "    print(\"\\nðŸŽ¤ STEP 1: Transcribing audio...\")\n",
        "\n",
        "    model = whisperx.load_model(\n",
        "        model_size,\n",
        "        CONFIG[\"device\"],\n",
        "        compute_type=CONFIG[\"compute_type\"]\n",
        "    )\n",
        "\n",
        "    transcribe_kwargs = {\n",
        "        \"batch_size\": CONFIG[\"batch_size\"]\n",
        "    }\n",
        "    if language:\n",
        "        transcribe_kwargs[\"language\"] = language\n",
        "\n",
        "    result = model.transcribe(audio, **transcribe_kwargs)\n",
        "\n",
        "    total_segments = len(result[\"segments\"])\n",
        "    total_words = sum(len(seg.get(\"words\", [])) for seg in result[\"segments\"])\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    if CONFIG[\"device\"] == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"âœ… Transcription complete!\")\n",
        "    print(f\"   Language: {result['language']}\")\n",
        "    print(f\"   Segments: {total_segments}\")\n",
        "    print(f\"   Total text length: {sum(len(seg['text']) for seg in result['segments'])} characters\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "ze37ysaFweNy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_transcription(segments, audio, language_code):\n",
        "    \"\"\"Align transcription for accurate word-level timestamps\"\"\"\n",
        "    print(\"\\nðŸŽ¯ STEP 2: Aligning for word-level timestamps...\")\n",
        "\n",
        "    try:\n",
        "        model_a, metadata = whisperx.load_align_model(\n",
        "            language_code=language_code,\n",
        "            device=CONFIG[\"device\"]\n",
        "        )\n",
        "\n",
        "        result = whisperx.align(\n",
        "            segments,\n",
        "            model_a,\n",
        "            metadata,\n",
        "            audio,\n",
        "            CONFIG[\"device\"],\n",
        "            return_char_alignments=False\n",
        "        )\n",
        "\n",
        "        total_words = sum(len(seg.get(\"words\", [])) for seg in result[\"segments\"])\n",
        "\n",
        "        del model_a\n",
        "        gc.collect()\n",
        "        if CONFIG[\"device\"] == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"âœ… Alignment complete!\")\n",
        "        print(f\"   Aligned words: {total_words}\")\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Alignment failed: {str(e)}\")\n",
        "        print(\"   Continuing with segment-level timestamps only...\")\n",
        "        return {\"segments\": segments, \"word_segments\": []}"
      ],
      "metadata": {
        "id": "_0y9t275wika"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_transcription(result):\n",
        "    \"\"\"Generate statistics about the transcription\"\"\"\n",
        "    print(\"\\nðŸ“Š TRANSCRIPTION STATISTICS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    segments = result[\"segments\"]\n",
        "\n",
        "    total_duration = max(seg[\"end\"] for seg in segments) if segments else 0\n",
        "    total_words = sum(len(seg.get(\"words\", [])) for seg in segments)\n",
        "    total_chars = sum(len(seg[\"text\"].strip()) for seg in segments)\n",
        "\n",
        "    print(f\"Total duration: {total_duration:.2f} seconds\")\n",
        "    print(f\"Total segments: {len(segments)}\")\n",
        "    print(f\"Total words: {total_words}\")\n",
        "    print(f\"Total characters: {total_chars}\")\n",
        "\n",
        "    if total_duration > 0:\n",
        "        print(f\"Words per minute: {(total_words / total_duration * 60):.1f}\")\n",
        "\n",
        "    pauses = []\n",
        "    for i in range(len(segments) - 1):\n",
        "        pause = segments[i+1][\"start\"] - segments[i][\"end\"]\n",
        "        if pause > 0:\n",
        "            pauses.append(pause)\n",
        "\n",
        "    if pauses:\n",
        "        print(f\"Average pause between segments: {sum(pauses)/len(pauses):.2f}s\")\n",
        "        print(f\"Longest pause: {max(pauses):.2f}s\")\n",
        "\n",
        "    word_durations = []\n",
        "    for seg in segments:\n",
        "        if \"words\" in seg:\n",
        "            for word in seg[\"words\"]:\n",
        "                duration = word[\"end\"] - word[\"start\"]\n",
        "                word_durations.append(duration)\n",
        "\n",
        "    if word_durations:\n",
        "        print(f\"Average word duration: {sum(word_durations)/len(word_durations):.3f}s\")\n",
        "\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "id": "Fe0jDqOlwnws"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(result, show_words=False, max_rows=50):\n",
        "    \"\"\"Display transcription results in formatted table\"\"\"\n",
        "    data = []\n",
        "\n",
        "    for seg in result[\"segments\"]:\n",
        "        text = seg[\"text\"].strip()\n",
        "        start = f\"{seg['start']:.2f}s\"\n",
        "        end = f\"{seg['end']:.2f}s\"\n",
        "        duration = f\"{seg['end'] - seg['start']:.2f}s\"\n",
        "\n",
        "        if show_words and \"words\" in seg:\n",
        "            for word in seg[\"words\"]:\n",
        "                data.append({\n",
        "                    \"Start\": f\"{word['start']:.2f}s\",\n",
        "                    \"End\": f\"{word['end']:.2f}s\",\n",
        "                    \"Duration\": f\"{word['end'] - word['start']:.3f}s\",\n",
        "                    \"Text\": word[\"word\"],\n",
        "                    \"Score\": f\"{word.get('score', 0):.2f}\"\n",
        "                })\n",
        "        else:\n",
        "            data.append({\n",
        "                \"Start\": start,\n",
        "                \"End\": end,\n",
        "                \"Duration\": duration,\n",
        "                \"Text\": text\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if len(df) > max_rows:\n",
        "        print(f\"Showing first {max_rows} rows of {len(df)} total...\")\n",
        "        display(HTML(df.head(max_rows).to_html(index=False)))\n",
        "    else:\n",
        "        display(HTML(df.to_html(index=False)))\n",
        "\n",
        "    return df\n",
        "\n",
        "def export_results(result, output_dir=\"output\", filename=\"transcript\"):\n",
        "    \"\"\"Export results in multiple formats\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    json_path = f\"{output_dir}/{filename}.json\"\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    srt_path = f\"{output_dir}/{filename}.srt\"\n",
        "    with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, seg in enumerate(result[\"segments\"], 1):\n",
        "            start = format_timestamp(seg[\"start\"])\n",
        "            end = format_timestamp(seg[\"end\"])\n",
        "            f.write(f\"{i}\\n{start} --> {end}\\n{seg['text'].strip()}\\n\\n\")\n",
        "\n",
        "    vtt_path = f\"{output_dir}/{filename}.vtt\"\n",
        "    with open(vtt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"WEBVTT\\n\\n\")\n",
        "        for i, seg in enumerate(result[\"segments\"], 1):\n",
        "            start = format_timestamp_vtt(seg[\"start\"])\n",
        "            end = format_timestamp_vtt(seg[\"end\"])\n",
        "            f.write(f\"{start} --> {end}\\n{seg['text'].strip()}\\n\\n\")\n",
        "\n",
        "    txt_path = f\"{output_dir}/{filename}.txt\"\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for seg in result[\"segments\"]:\n",
        "            f.write(f\"{seg['text'].strip()}\\n\")\n",
        "\n",
        "    csv_path = f\"{output_dir}/{filename}.csv\"\n",
        "    df_data = []\n",
        "    for seg in result[\"segments\"]:\n",
        "        df_data.append({\n",
        "            \"start\": seg[\"start\"],\n",
        "            \"end\": seg[\"end\"],\n",
        "            \"text\": seg[\"text\"].strip()\n",
        "        })\n",
        "    pd.DataFrame(df_data).to_csv(csv_path, index=False)\n",
        "\n",
        "    print(f\"\\nðŸ’¾ Results exported to '{output_dir}/' directory:\")\n",
        "    print(f\"   âœ“ {filename}.json (full structured data)\")\n",
        "    print(f\"   âœ“ {filename}.srt (subtitles)\")\n",
        "    print(f\"   âœ“ {filename}.vtt (web video subtitles)\")\n",
        "    print(f\"   âœ“ {filename}.txt (plain text)\")\n",
        "    print(f\"   âœ“ {filename}.csv (timestamps + text)\")\n",
        "\n",
        "def format_timestamp(seconds):\n",
        "    \"\"\"Convert seconds to SRT timestamp format\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    millis = int((seconds % 1) * 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
        "\n",
        "def format_timestamp_vtt(seconds):\n",
        "    \"\"\"Convert seconds to VTT timestamp format\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    millis = int((seconds % 1) * 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}\"\n",
        "\n",
        "def batch_process_files(audio_files, output_dir=\"batch_output\"):\n",
        "    \"\"\"Process multiple audio files in batch\"\"\"\n",
        "    print(f\"\\nðŸ“¦ Batch processing {len(audio_files)} files...\")\n",
        "    results = {}\n",
        "\n",
        "    for i, audio_path in enumerate(audio_files, 1):\n",
        "        print(f\"\\n[{i}/{len(audio_files)}] Processing: {Path(audio_path).name}\")\n",
        "        try:\n",
        "            result, _ = process_audio_file(audio_path, show_output=False)\n",
        "            results[audio_path] = result\n",
        "\n",
        "            filename = Path(audio_path).stem\n",
        "            export_results(result, output_dir, filename)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {audio_path}: {str(e)}\")\n",
        "            results[audio_path] = None\n",
        "\n",
        "    print(f\"\\nâœ… Batch processing complete! Processed {len(results)} files.\")\n",
        "    return results\n",
        "\n",
        "def extract_keywords(result, top_n=10):\n",
        "    \"\"\"Extract most common words from transcription\"\"\"\n",
        "    from collections import Counter\n",
        "    import re\n",
        "\n",
        "    text = \" \".join(seg[\"text\"] for seg in result[\"segments\"])\n",
        "\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
        "                  'of', 'with', 'is', 'was', 'are', 'were', 'be', 'been', 'being',\n",
        "                  'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
        "                  'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those'}\n",
        "\n",
        "    filtered_words = [w for w in words if w not in stop_words and len(w) > 2]\n",
        "\n",
        "    word_counts = Counter(filtered_words).most_common(top_n)\n",
        "\n",
        "    print(f\"\\nðŸ”‘ Top {top_n} Keywords:\")\n",
        "    for word, count in word_counts:\n",
        "        print(f\"   {word}: {count}\")\n",
        "\n",
        "    return word_counts"
      ],
      "metadata": {
        "id": "BTTa6bDFws-F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_file(audio_path, show_output=True, analyze=True):\n",
        "    \"\"\"Complete WhisperX pipeline\"\"\"\n",
        "    if show_output:\n",
        "        print(\"=\"*70)\n",
        "        print(\"ðŸŽµ WhisperX Advanced Tutorial\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "    audio, duration = load_and_analyze_audio(audio_path)\n",
        "\n",
        "    result = transcribe_audio(audio, CONFIG[\"model_size\"], CONFIG[\"language\"])\n",
        "\n",
        "    aligned_result = align_transcription(\n",
        "        result[\"segments\"],\n",
        "        audio,\n",
        "        result[\"language\"]\n",
        "    )\n",
        "\n",
        "    if analyze and show_output:\n",
        "        analyze_transcription(aligned_result)\n",
        "        extract_keywords(aligned_result)\n",
        "\n",
        "    if show_output:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ðŸ“‹ TRANSCRIPTION RESULTS\")\n",
        "        print(\"=\"*70)\n",
        "        df = display_results(aligned_result, show_words=False)\n",
        "\n",
        "        export_results(aligned_result)\n",
        "    else:\n",
        "        df = None\n",
        "\n",
        "    return aligned_result, df\n",
        "\n",
        "# Example 1: Process sample audio\n",
        "# audio_path = download_sample_audio()\n",
        "# result, df = process_audio_file(audio_path)\n",
        "\n",
        "# Example 2: Show word-level details\n",
        "# result, df = process_audio_file(audio_path)\n",
        "# word_df = display_results(result, show_words=True)\n",
        "\n",
        "# Example 3: Process your own audio\n",
        "# audio_path = \"your_audio.wav\"  # or .mp3, .m4a, etc.\n",
        "# result, df = process_audio_file(audio_path)\n",
        "\n",
        "# Example 4: Batch process multiple files\n",
        "# audio_files = [\"audio1.mp3\", \"audio2.wav\", \"audio3.m4a\"]\n",
        "# results = batch_process_files(audio_files)\n",
        "\n",
        "# Example 5: Use larger model for better accuracy\n",
        "# CONFIG[\"model_size\"] = \"large-v2\"\n",
        "# result, df = process_audio_file(\"audio.mp3\")\n",
        "\n",
        "print(\"\\nâœ¨ Setup complete! Uncomment examples above to run.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTiL7SdJvxE3",
        "outputId": "699175d4-d289-4435-976f-c66a1e62f0d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ¨ Setup complete! Uncomment examples above to run.\n"
          ]
        }
      ]
    }
  ]
}